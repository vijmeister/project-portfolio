{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"sentiment_analysis.ipynb","provenance":[],"authorship_tag":"ABX9TyNsnoqu+iF5/zdi3I+I12K/"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"_jG3xGFx3Mhp","colab_type":"text"},"source":["Code adapted from https://www.kaggle.com/chiranjeevbit/movie-review-prediction"]},{"cell_type":"code","metadata":{"id":"8LygAGuoRljs","colab_type":"code","outputId":"34d70433-c7ea-49eb-92e8-6ae9915bd5fa","executionInfo":{"status":"ok","timestamp":1590777599417,"user_tz":240,"elapsed":775,"user":{"displayName":"Vijay","photoUrl":"","userId":"10139444167783907979"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["from google.colab import drive \n","drive.mount(\"/content/gdrive\")"],"execution_count":47,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"r5af9hd7giTs","colab_type":"text"},"source":["# Imports and Initializations"]},{"cell_type":"code","metadata":{"id":"8BHdMDnS2NeS","colab_type":"code","outputId":"258d3850-53d3-4de9-8a80-43bbdbf27972","executionInfo":{"status":"ok","timestamp":1590777599935,"user_tz":240,"elapsed":1286,"user":{"displayName":"Vijay","photoUrl":"","userId":"10139444167783907979"}},"colab":{"base_uri":"https://localhost:8080/","height":102}},"source":["import os\n","import random\n","import re\n","\n","import bs4\n","import keras\n","import pandas as pd\n","import nltk\n","import numpy as np\n","import sklearn\n","import tensorflow as tf\n","\n","nltk.download(\"punkt\")\n","nltk.download(\"wordnet\")"],"execution_count":48,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":48}]},{"cell_type":"code","metadata":{"id":"ca4N9YwYhhY8","colab_type":"code","colab":{}},"source":["BASE_DIR = \"\"\n","GLOVE_DIR = \"/content/gdrive/My Drive/glove.6B/\"\n","TEXT_DATA_DIR = \"/content/gdrive/My Drive/rt/\"\n","MAX_SEQUENCE_LENGTH = 48\n","MAX_NUM_WORDS = 13738\n","EMBEDDING_DIM = 300\n","batch_size = 32\n","tf.random.set_seed(123)\n","random.seed(123)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DWvMao7RABvY","colab_type":"text"},"source":["# Read Inputs"]},{"cell_type":"code","metadata":{"id":"f1eqRAyyi7ag","colab_type":"code","outputId":"2bbd3b93-0018-476b-a7de-8a1456390a91","executionInfo":{"status":"ok","timestamp":1590777599937,"user_tz":240,"elapsed":1278,"user":{"displayName":"Vijay","photoUrl":"","userId":"10139444167783907979"}},"colab":{"base_uri":"https://localhost:8080/","height":204}},"source":["train = pd.read_csv(\"/content/gdrive/My Drive/rt/train.tsv\", sep=\"\\t\")\n","train.head()"],"execution_count":50,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>PhraseId</th>\n","      <th>SentenceId</th>\n","      <th>Phrase</th>\n","      <th>Sentiment</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>A series of escapades demonstrating the adage ...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>A series of escapades demonstrating the adage ...</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>A series</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>1</td>\n","      <td>A</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>1</td>\n","      <td>series</td>\n","      <td>2</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   PhraseId  ...  Sentiment\n","0         1  ...          1\n","1         2  ...          2\n","2         3  ...          2\n","3         4  ...          2\n","4         5  ...          2\n","\n","[5 rows x 4 columns]"]},"metadata":{"tags":[]},"execution_count":50}]},{"cell_type":"code","metadata":{"id":"0l5qkhPlmpa3","colab_type":"code","colab":{}},"source":["\n","X = train.Phrase\n","X = X.astype(\"str\")\n","y = np.asarray(train.Sentiment.astype(\"int\"))\n","y = keras.utils.to_categorical(y)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"0gjzdbYnJgbR","colab_type":"code","outputId":"2c230730-acae-441b-e2d7-b922ac354c3d","executionInfo":{"status":"ok","timestamp":1590777618170,"user_tz":240,"elapsed":19502,"user":{"displayName":"Vijay","photoUrl":"","userId":"10139444167783907979"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["\n","embeddings_index = {}\n","with open(os.path.join(GLOVE_DIR, \"glove.6B.300d.txt\")) as f:\n","    for line in f:\n","        word, coefs = line.split(maxsplit=1)\n","        coefs = np.fromstring(coefs, \"f\", sep=\" \")\n","        embeddings_index[word] = coefs\n","\n","print(\"Found %s word vectors.\" % len(embeddings_index))"],"execution_count":52,"outputs":[{"output_type":"stream","text":["Found 400000 word vectors.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"q3QZz2cA_2_B","colab_type":"text"},"source":["# Preprocess"]},{"cell_type":"code","metadata":{"id":"KswcUi0sWcia","colab_type":"code","colab":{}},"source":["def clean_sentences(sent):\n","    \"\"\"\n","    1. remove html content\n","    2. remove non-alphabetic characters\n","    3. tokenize the sentences\n","    4. lemmatize each word to its lemma\n","\n","    Input:\n","      sent(str): text to be preprocessed\n","    Returns:\n","      lemma_words(list): lemmatized words\n","    \"\"\"\n","    review_text = bs4.BeautifulSoup(sent).get_text()\n","    \n","    review_text = re.sub(\"[^a-zA-Z]\",\" \", review_text)\n","\n","    words = nltk.tokenize.word_tokenize(review_text.lower())\n","\n","    lemmatizer = nltk.stem.WordNetLemmatizer()\n","    lemma_words = [lemmatizer.lemmatize(i) for i in words]\n","    \n","\n","    return lemma_words"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"YUKHjKwAqZU4","colab_type":"code","outputId":"c6addb51-d2f5-46fa-cb9d-2d00a579a952","executionInfo":{"status":"ok","timestamp":1590777670793,"user_tz":240,"elapsed":72115,"user":{"displayName":"Vijay","photoUrl":"","userId":"10139444167783907979"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["X = X.apply(clean_sentences)\n","x_train, x_val, y_train, y_val = sklearn.model_selection.train_test_split(X,y,test_size=0.2,stratify=y)\n","\n","tokenizer = keras.preprocessing.text.Tokenizer(num_words=MAX_NUM_WORDS)\n","tokenizer.fit_on_texts(list(x_train))\n","\n","x_train = tokenizer.texts_to_sequences(x_train)\n","x_val = tokenizer.texts_to_sequences(x_val)\n","\n","x_train = keras.preprocessing.sequence.pad_sequences(x_train, maxlen=MAX_SEQUENCE_LENGTH)\n","x_val = keras.preprocessing.sequence.pad_sequences(x_val, maxlen=MAX_SEQUENCE_LENGTH)\n"],"execution_count":54,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/bs4/__init__.py:273: UserWarning: \"b'.'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n","  ' Beautiful Soup.' % markup)\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"g_dTypUnJ3bH","colab_type":"code","colab":{}},"source":["# prepare embedding matrix\n","word_index = tokenizer.word_index\n","num_words = min(MAX_NUM_WORDS, len(word_index) + 1)\n","embedding_matrix = np.zeros((num_words, EMBEDDING_DIM))\n","for word, i in word_index.items():\n","    if i >= MAX_NUM_WORDS:\n","        continue\n","    embedding_vector = embeddings_index.get(word)\n","    if embedding_vector is not None:\n","        # words not found in embedding index will be all-zeros.\n","        embedding_matrix[i] = embedding_vector\n","\n","# note that we set trainable = False so as to keep the embeddings fixed\n","embedding_layer = keras.layers.Embedding(num_words,\n","                            EMBEDDING_DIM,\n","                            embeddings_initializer=keras.initializers.Constant(embedding_matrix),\n","                            input_length=MAX_SEQUENCE_LENGTH,\n","                            trainable=False)\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CWZTFkA9_vLT","colab_type":"text"},"source":["# Train Model"]},{"cell_type":"code","metadata":{"id":"ztLr5c9-I_YA","colab_type":"code","outputId":"8b2a9ef0-c2bc-4851-8484-69cfebc9c407","executionInfo":{"status":"ok","timestamp":1590784221639,"user_tz":240,"elapsed":2022347,"user":{"displayName":"Vijay","photoUrl":"","userId":"10139444167783907979"}},"colab":{"base_uri":"https://localhost:8080/","height":918}},"source":["early_stopping = keras.callbacks.EarlyStopping(min_delta = 0.001, mode = \"max\", monitor=\"val_accuracy\", patience = 2)\n","callback = [early_stopping]\n","\n","print(\"Build model...\")\n","\n","model=keras.Sequential()\n","model.add(keras.layers.InputLayer(input_shape=(MAX_SEQUENCE_LENGTH,), dtype=\"int32\"))\n","model.add(embedding_layer)\n","model.add(keras.layers.LSTM(256,dropout=0.5, recurrent_dropout=0.5,return_sequences=True))\n","model.add(keras.layers.LSTM(128,dropout=0.5, recurrent_dropout=0.5,return_sequences=True))\n","model.add(keras.layers.LSTM(64,dropout=0.5, recurrent_dropout=0.5,return_sequences=False))\n","model.add(keras.layers.Dense(300,activation=\"relu\"))\n","model.add(keras.layers.Dropout(0.5))\n","model.add(keras.layers.Dense(5,activation=\"softmax\"))\n","model.compile(loss=\"categorical_crossentropy\",optimizer=keras.optimizers.Adam(lr=0.001),metrics=[\"accuracy\"])\n","model.summary()\n","\n","print(\"Train...\")\n","history=model.fit(x_train, y_train, validation_data=(x_val, y_val),epochs=15, batch_size=256, verbose=1, callbacks=callback)"],"execution_count":65,"outputs":[{"output_type":"stream","text":["Build model...\n","Model: \"sequential_9\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding_3 (Embedding)      (None, 48, 300)           4121400   \n","_________________________________________________________________\n","lstm_17 (LSTM)               (None, 48, 256)           570368    \n","_________________________________________________________________\n","lstm_18 (LSTM)               (None, 48, 128)           197120    \n","_________________________________________________________________\n","lstm_19 (LSTM)               (None, 64)                49408     \n","_________________________________________________________________\n","dense_17 (Dense)             (None, 300)               19500     \n","_________________________________________________________________\n","dropout_9 (Dropout)          (None, 300)               0         \n","_________________________________________________________________\n","dense_18 (Dense)             (None, 5)                 1505      \n","=================================================================\n","Total params: 4,959,301\n","Trainable params: 837,901\n","Non-trainable params: 4,121,400\n","_________________________________________________________________\n","Train...\n","Train on 124848 samples, validate on 31212 samples\n","Epoch 1/15\n","124848/124848 [==============================] - 146s 1ms/step - loss: 1.1148 - accuracy: 0.5497 - val_loss: 0.9464 - val_accuracy: 0.6060\n","Epoch 2/15\n","124848/124848 [==============================] - 147s 1ms/step - loss: 0.9938 - accuracy: 0.5898 - val_loss: 0.9156 - val_accuracy: 0.6185\n","Epoch 3/15\n","124848/124848 [==============================] - 148s 1ms/step - loss: 0.9639 - accuracy: 0.5989 - val_loss: 0.8884 - val_accuracy: 0.6274\n","Epoch 4/15\n","124848/124848 [==============================] - 145s 1ms/step - loss: 0.9462 - accuracy: 0.6067 - val_loss: 0.8717 - val_accuracy: 0.6337\n","Epoch 5/15\n","124848/124848 [==============================] - 143s 1ms/step - loss: 0.9267 - accuracy: 0.6156 - val_loss: 0.8593 - val_accuracy: 0.6419\n","Epoch 6/15\n","124848/124848 [==============================] - 145s 1ms/step - loss: 0.9143 - accuracy: 0.6200 - val_loss: 0.8455 - val_accuracy: 0.6451\n","Epoch 7/15\n","124848/124848 [==============================] - 144s 1ms/step - loss: 0.9028 - accuracy: 0.6236 - val_loss: 0.8392 - val_accuracy: 0.6490\n","Epoch 8/15\n","124848/124848 [==============================] - 145s 1ms/step - loss: 0.8916 - accuracy: 0.6303 - val_loss: 0.8360 - val_accuracy: 0.6510\n","Epoch 9/15\n","124848/124848 [==============================] - 147s 1ms/step - loss: 0.8858 - accuracy: 0.6309 - val_loss: 0.8235 - val_accuracy: 0.6572\n","Epoch 10/15\n","124848/124848 [==============================] - 144s 1ms/step - loss: 0.8761 - accuracy: 0.6350 - val_loss: 0.8166 - val_accuracy: 0.6597\n","Epoch 11/15\n","124848/124848 [==============================] - 145s 1ms/step - loss: 0.8697 - accuracy: 0.6386 - val_loss: 0.8126 - val_accuracy: 0.6610\n","Epoch 12/15\n","124848/124848 [==============================] - 141s 1ms/step - loss: 0.8600 - accuracy: 0.6416 - val_loss: 0.8043 - val_accuracy: 0.6666\n","Epoch 13/15\n","124848/124848 [==============================] - 141s 1ms/step - loss: 0.8558 - accuracy: 0.6437 - val_loss: 0.7985 - val_accuracy: 0.6660\n","Epoch 14/15\n","124848/124848 [==============================] - 139s 1ms/step - loss: 0.8499 - accuracy: 0.6463 - val_loss: 0.7938 - val_accuracy: 0.6666\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"wuMzguYi_gzh","colab_type":"text"},"source":["# Preparing submission file"]},{"cell_type":"code","metadata":{"id":"b72LvDOeoRwp","colab_type":"code","outputId":"eb75a60a-f765-45e5-f596-f35d579eb272","executionInfo":{"status":"ok","timestamp":1590784369955,"user_tz":240,"elapsed":22808,"user":{"displayName":"Vijay","photoUrl":"","userId":"10139444167783907979"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["test = pd.read_csv(\"/content/gdrive/My Drive/rt/test.tsv\", sep=\"\\t\")\n","\n","X_test = test.Phrase.astype(\"str\")\n","X_test = X_test.apply(clean_sentences)\n","\n","sequences = tokenizer.texts_to_sequences(X_test.to_list())\n","test_data = keras.preprocessing.sequence.pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)"],"execution_count":66,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/bs4/__init__.py:273: UserWarning: \"b'.'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n","  ' Beautiful Soup.' % markup)\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"UJYu2FpXEPkn","colab_type":"code","colab":{}},"source":["y_pred=model.predict_classes(test_data)\n","\n","sub_file = pd.read_csv(\"/content/gdrive/My Drive/rt/sampleSubmission.csv\",sep=\",\")\n","sub_file.Sentiment=y_pred\n","sub_file.to_csv(\"sub_exp.csv\",index=False)\n","!cp sub_exp.csv \"/content/gdrive/My Drive/rt/submissions/\""],"execution_count":0,"outputs":[]}]}